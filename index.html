<html>

<head>
<meta http-equiv="Content-Language" content="zh-tw">
<meta http-equiv="Content-Type" content="text/html; charset=big5">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>Tom Ko</title>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-37646687-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>

<body>

<div id="container">
<div id="logo">
<h1>Tom, Ko Yu Ting  <img src="./images/Tom_head.jpg" align="middle" height="200"/></h1>
</div>

<div id="main">
<a name="bio"></a>

<p>
<i>The LORD said, “If as one people speaking the same language they have begun to do this, then nothing they plan to do will be impossible for them.
Come, let us go down and confuse their language so they will not understand each other.” (Genesis 11: 6-7) </i>
</p>

<p>
This is the reason why there are so many languages in the world. Although it is God's intention to confuse human being with the languages, he still gives us a chance to break the spell. God implies that nothing will be impossible when human being get unified. Thus, I believe that everything is achievable with technology.
</p>






<h3>Announcement</h3>
<p>
<!--  <a href="http://www.noahlab.com.hk/" target=_top>Huawei Noah's Ark Lab </a> -->
I am currently recruiting intern students in the field of speech and natural language processing.
Candidates need to be self-motivated and good at programming (e.g. C++, python).
If you are interested in speech or machine translation related research, please feel free to contact me.
</p>


<P>
<HR>
</P>
<p>

<a name="contact"></a>
<h3>Contact:</h3>
<p>
Email: tomkocse@gmail.com<br>
</p>

<a name="bio"></a>
<h3>Biography</h3>
<p>
Tom, Ko Yu Ting received the B.Eng. degree in computer engineering from the Chinese University of Hong Kong in 2003. Then he received the M.Phil. and Ph.D. degree in computer science and engineering from the Hong Kong University of Science and Technology in 2010 and 2014 respectively.
Throughout his postgraduate studies, he was supervised by
<a href="http://www.cs.ust.hk/~mak" target=_top>Professor Brian Mak</a>.
After that, he joined 
<a href="http://www.noahlab.com.hk/" target=_top>Huawei Noah's Ark Lab </a>
as a research scientist.
In 2019, he worked as an assistant professor at
<a href="http://www.sustc.edu.cn/en//" target=_top>Southern University of Science and Technology</a>
in China.
In 2021, he joined ByteDance AI as a research scientist.
His research interests include speech recognition and natural language processing. 
</p>

<P>
<HR>
</P>
<p>


<a name="bio"></a>
<h3>Education</h3>
<p> <B> Ph.D. </B> in Computer Science and Engineering  in HKUST, 2014 </p> 
<p> <B> M.Phil. </B> in Computer Science and Engineering  in HKUST, 2010 </p> 
<p> <B> M.Sc. </B> in IC Design Engineering  in HKUST, 2007 </p> 
<p> <B> Bachelor Degree </B> in Computer Engineering  in CUHK, 2003 </p> 

<P>
<HR>
</P>
<p>


<a name="publ"></a>
<h3>Publications</h3>
<!-- Format Reference (Conference)
<p>
<b>Author1</b>, Auhtor2, and Author 3,
"Title", in <i>Proc. XXX</i>, year, pages.
</p>
-->


<h4>[Conference Papers]</h4>
<UL>

<LI><p>
Fengpeng Yue, Yan Feng, Lei He, <b>Tom Ko</b>, Yu Zhang
"EXPLORING MACHINE SPEECH CHAIN FOR DOMAIN ADAPTATION", in
<i> Proceedings of ICASSP, May, 2022, Singapore </i>
</p>

<LI><p>
Rui Wang, Junyi Ao, Long Zhou, Shujie Liu, Zhihua Wei, <b>Tom Ko</b>, Qing Li, Yu Zhang
"MULTI-VIEW SELF-ATTENTION BASED TRANSFORMER FOR SPEAKER RECOGNITION", in
<i> Proceedings of ICASSP, May, 2022, Singapore </i>
</p>

<LI><p>
Jingsong Wang, Yuxuan He, Chunyu Zhao, Qijie Shao, Wei-Wei Tu, <b>Tom Ko</b>, Hung-yi Lee, Lei Xie
"Auto-KWS 2021 Challenge: Task, Datasets, and Baselines", in
<i> Proceedings of Interspeech, September, 2021, Brno, Czech Republic </i>
</p>

<LI><p>
Qiushi Huang, <b>Tom Ko</b>, H. Lilian Tang, Xubo Liu, Bo Wu
"Token-Level Supervised Contrastive Learning for Punctuation Restoration", in
<i> Proceedings of Interspeech, September, 2021, Brno, Czech Republic </i>
</p>

<LI><p>
Yangbin Chen, <b>Tom Ko</b>, Jianping Wang
"A Meta-Learning Approach for User-Defined Spoken Term Classification with Varying Classes and Examples", in
<i> Proceedings of Interspeech, September, 2021, Brno, Czech Republic </i>
</p>


<LI><p>
Junyi Ao, <b>Tom Ko</b>
"Improving Attention-based End-to-end ASR by Incorporating an N-gram Neural Network", in
<i> Proceedings of ISCSLP, January, 2021, Hong Kong </i>
</p>

<LI><p>
Fengpeng Yue, <b>Tom Ko</b>
"An Investigation of Positional Encoding in Transformer-based End-to-end Speech Recognition", in
<i> Proceedings of ISCSLP, January, 2021, Hong Kong </i>
</p>

<LI><p>
Yangbin Chen, <b>Tom Ko</b>, Lifeng Shang, Xiao Chen, Xin Jiang, Qing Li
"An Investigation of Few-Shot Learning in Spoken Term Classification", in
<i> Proceedings of Interspeech, September, 2020, Shanghai, China </i>
</p>

<LI><p>
Yangbin Chen, YUN MA, <b>Tom Ko</b>, JIANPING WANG, Qing Li
"MetaMix: Improved Meta-Learning with Interpolation based Consistency Regularization", in
<i> ICPR 2020</i>
</p>


<LI><p>
Jingsong Wang, <b>Tom Ko</b>, Zhen Xu, Xiawei Guo, Souxiang Liu, Wei-Wei Tu, Lei Xie
"AutoSpeech 2020: The Second Automated Machine Learning Challenge for Speech Classification", in
<i> Proceedings of Interspeech, September, 2020, Shanghai, China </i>
</p>

<LI><p>
<b>Tom Ko</b>, Yangbin Chen, Qing Li
"Prototypical Networks for Small Footprint Text-independent Speaker Verification", in
<i> Proceedings of ICASSP, May, 2020, Barcelona, Spain </i>
</p>

<LI><p>
Yingke Zhu, <b>Tom Ko</b>, Brian Mak
"Mixup Learning Strategies for Text-independent Speaker Verification", in
<i> Proceedings of Interspeech, September, 2019, Graz, Austria </i>
</p>

<LI><p>
Yingke Zhu, <b>Tom Ko</b>, David Snyder, Brian Mak, Daniel Povey
"Self-Attentive Speaker Embeddings for Text-Independent Speaker Verification", in
<i> Proceedings of Interspeech, September, 2018, Hyderabad, India </i>
</p>

<LI><p>
Zhen Qin, <b>Tom Ko</b>, Guangjian Tian
"Long Distance Voice Channel Diagnosis Using Deep Neural Networks", in
<i> Proceedings of Interspeech, September, 2018, Hyderabad, India </i>
</p>

<LI><p>
<b>Tom Ko</b>, Vijayaditya Peddinti, Daniel Povey,  Michael L. Seltzer, Sanjeev Khudanpur
"A study on data augmentation of reverberant speech for robust speech recognition", in
<i>Proceedings of ICASSP, March, 2017, New Orleans, USA</i>
</p>
<LI><p>
Yajie Miao, Mohammad Gowayyed, Xingyu Na, <b>Tom Ko</b>, Florian Metze, and Alexander Waibel
"An Empirical Exploration of CTC Acoustic Models", in
<i>Proceedings of ICASSP, March, 2016, Shanghai, China</i>
</p>
<LI><p>
Vijayaditya Peddinti, Guoguo Chen, Vimal Manohar, <b>Tom Ko</b>, Daniel Povey, Sanjeev Khudanpur
"JHU ASpIRE system : Robust LVCSR with TDNNs, i-vector adaptation and RNN-LMs", in
<i> IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), December, 2015, Scottsdale, Arizona, USA</i>
</p>
<LI><p>
<b>Tom Ko</b>, Vijayaditya Peddinti, Daniel Povey, Sanjeev Khudanpur
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/IS151532.pdf" target=_top>
Audio Augmentation for Speech Recognition</a>", in
<i> Proceedings of Interspeech, September, 2015, Dresden, Germany </i>
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/IS2015-poster.pdf" target=_top>
(poster) </a>
</p>
<LI><p>
<b>Tom Ko</b>, Brian Mak, Dongpeng Chen
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2012-0004097.pdf" target=_top>
Modeling Inter-cluster and Intra-cluster Discrimination Among Triphones</a>", in
<i> Proceedings of the International Symposium of Chinese Spoken Language Processing, September, 2014, Singapore </i>
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2012-oral.pptx" target=_top>
(poster) </a>
</p>
<LI><p>
<b>Tom Ko</b>, Brian Mak and Cheung-Chi Leung
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2012-0004097.pdf" target=_top>
SUBSPACE GAUSSIAN MIXTURE MODEL WITH STATE-DEPENDENT SUBSPACE DIMENSIONS</a>", in
<i> Proceedings of ICASSP, pages 1744-1748, May, 2014, Florence, Italy </i>
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2012-oral.pptx" target=_top>
(poster) </a>
</p>
<LI><p>
<b>Tom Ko</b> and Brian Mak,
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2012-0004097.pdf" target=_top>
DERIVATION OF EIGENTRIPHONES BY WEIGHTED PRINCIPAL COMPONENT ANALYSIS</a>", in
<i> Proceedings of ICASSP, pages 4097-4100, March, 2012, Kyoto, Japan </i> 
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2012-oral.pptx" target=_top>
(oral) </a>
</p>
<LI><p>
<b>Tom Ko</b> and Brian Mak,
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/IS110731.pdf" target=_top>
A FULLY AUTOMATED DERIVATION OF STATE-BASED EIGENTRIPHONES FOR TRIPHONE MODELING WITH NO TIED STATES USING REGULARIZATION</a>", in
<i> Proceedings of Interspeech, pages 781-784, August, 2011, Florence, Italy </i>
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/IS2011-oral.pdf" target=_top>
(oral) </a>
</p>
<LI><p>
<b>Tom Ko</b> and Brian Mak,
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2011-0004892.pdf" target=_top>
EIGENTRIPHONES: A BASIS FOR CONTEXT-DEPENDENT ACOUSTIC MODELING</a>", in
<i> Proceedings of ICASSP, pages 4892-4895, May, 2011, Prague, Czech Republic </i> 
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2011-poster.pdf" target=_top>
(poster) </a>
</p>
<LI><p>
Brian Mak and <b>Tom Ko</b>,
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ISCSLP2010-05684839.pdf" target=_top>
Problems of Modeling Phone Deletion in Conversational Speech for Speech Recognition</a>", in
<i> Proceedings of the International Symposium of Chinese Spoken Language Processing, pages 114-118, Nov, 2010 ,Taiwan</i>
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ISCSLP2010-oral.ppt" target=_top>
(oral) </a>
</p>
<LI><p>
<b>Tom Ko</b> and Brian Mak,
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2010-0004858.pdf" target=_top>
IMPROVING SPEECH RECOGNITION BY EXPLICIT MODELING OF PHONE DELETIONS</a>", in
<i> Proceedings of ICASSP, pages 4858-4861, March, 2010, Dallas, Texas, USA </i>
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/ICASSP2010-poster.pdf" target=_top>
(poster) </a>
</p>
<LI><p>
Brian Mak and <b>Tom Ko</b>,
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/IS090470.pdf" target=_top>
Automatic Estimation of Decoding Parameters Using Large-Margin Iterative Linear Programming</a>", in
<i> Proceedings of Interspeech, pages 1219-1222, Sept, 2009, Brighton, U.K. </i>
<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/IS2009-poster.pdf" target=_top>
(poster) </a>
</p>
<LI><p>
Brian Mak and <b>Tom Ko</b>,
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/IS080754.pdf" target=_top>
Min-max Discriminative Training of Decoding Parameters Using Iterative Linear Programming</a>", in
<i> Proceedings of Interspeech, pages 915-918, Sept, 2008, Brisbane, Australia </i>
</p>
<!--
<LI><p>
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/temp.pdf" target=_top>
TEMP</a>", in
</p>
<LI><p>
"<a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/temp.htm" target=_top>
TEMP</a>", in
</p>
<LI><p>
-->

</UL>

<h4>[Journal Papers]</h4>
<UL>
<LI><p>
<b>Tom Ko</b> and Brian Mak,
"Eigentrigraphemes for Under-Resourced Languages",
<i> Speech Communications, volume 56, pages 132-141, January, 2014 </i> </p>
<LI><p>
<b>Tom Ko</b> and Brian Mak,
"Eigentriphones for Context-dependent Acoustic Modeling",
<i> IEEE Transactions on Audio, Speech and Language Processing, volume 21, number 6, pages 1285-1294, 2013 </i>
</p>
</UL>

<h4>[Thesis]</h4>
<b><a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/Tom_Mphil_thesis_final.pdf" target=_top>
Phone Deletion Modeling in Speech Recognition</a> (M.Phil.)</b>
<p>
</p>
<b><a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/paper/Tom_Mphil_thesis_final.pdf" target=_top>
Distinct Acoustic Modeling for Automatic Speech Recognition</a> (Ph.D.)</b>

<h4>[Award]</h4>
<b><a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/images/award_pgforum2010.jpg" target=_top>
2nd best presentation in Signal Processing Postgraduate Forum 2010 organized by the IEEE Hong Kong Chapter</a></b>

<p>
</p>


<b><a href="https://github.com/tomkocse/tomkocse.github.io/raw/master/images/BestTAaward.jpg" target=_top>
Professor Samuel Chanson Best Teaching Assistant Award 2011-12</a></b>

<P>
<HR>
</P>
<p>

<a name="service"></a>
<H1>Services</H1>

<h4>[Teaching Assistant]</h4>
<UL>
<LI><p>  Comp102 Computer and Programming Fundamental I </p></LI> 
<LI><p>  Comp103 Computer and Programming Fundamental II </p></LI>
<LI><p>  Comp104 Programming Fundamentals and Methodology </p></LI>
<LI><p>  Comp1022Q Introduction to Computing with Excel VBA </p></LI>
</UL>

<P>
<HR>
</P>
<p>




<!-- <h3>My music label:</h3>
	<p><a href="http://www.youtube.com/watch?v=XD9uhaKFos8" target=_top>Canon Rock</a></p>
-->


</body>

